# ğŸš€ Titanic ETL Data Pipeline Project

---

## ğŸ“Œ Project Title:
**ETL Data Pipeline for Titanic Dataset using Pandas and Scikit-learn**

---

## ğŸ¯ Objective / Aim of the Project:

The objective of this project is to develop an **automated ETL (Extract, Transform, Load) pipeline** using Python libraries like **Pandas** and **Scikit-learn**. This pipeline processes raw Titanic dataset (`tested.csv`) by cleaning, transforming, and saving it for further analysis or machine learning tasks.

---

## ğŸ§° Technologies & Libraries Used:

- **Programming Language:** Python 3.x  
- **Libraries:**
  - `pandas` â€“ for data manipulation
  - `scikit-learn` â€“ for data preprocessing and transformation
  - `joblib` â€“ for saving the pipeline and processed data

---

## ğŸ”„ ETL Process Explanation:

### âœ… 1. Extract
- Load raw data from `tested.csv` using `pandas.read_csv()`.

### âœ… 2. Transform
- Drop unnecessary or sparse columns: `Name`, `Ticket`, `Cabin`, `PassengerId`.
- Handle missing values:
  - `Age`, `Fare` â†’ imputed using mean
  - `Embarked` â†’ imputed using most frequent value
- Encode categorical columns: `Sex`, `Embarked` using One-Hot Encoding.
- Scale numerical features: `Age`, `Fare`, `SibSp`, `Parch`, `Pclass` using `StandardScaler`.

### âœ… 3. Load
- Split the dataset into training and testing sets.
- Save the processed data as `processed_titanic_data.pkl`.
- Save the transformation pipeline as `titanic_pipeline.joblib` for future reuse.

---

## â–¶ï¸ How to Run the Project:

### 1. Install required libraries:

```bash
pip install pandas scikit-learn joblib
